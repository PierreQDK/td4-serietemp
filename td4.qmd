---
format: 
  pdf:
    documentclass: article
    classoption: ["a4paper", "12pt", "fleqn"]
    geometry: top=2.5cm, bottom=2.5cm, left=2.5cm, right=2.5cm
    number-sections: true
    number-depth: 8
    toc: false  # Désactiver le sommaire automatique
header-includes: |
  \usepackage{hyperref}  % Liens cliquables
  \hypersetup{hidelinks}  % Désactive complètement la mise en couleur des liens
editor: 
  markdown: 
    wrap: 72
---

\begin{titlepage}
    \begin{center}
        {\LARGE \textbf{Séries temporelles univariées}}\\
        \vspace{0.5cm}
        {\Large M1 ECAP -- TD4 -- Année 2024/2025}\\
        
        \vspace{8cm}
        
        {\Large \textbf{TD4 : Analyse de la non-stationarité et racines unitaires}}\\
        \vspace{0.5cm}
        \textit{Responsable d'enseignement : Benoît SÉVI}\\
        \href{mailto:benoit.sevi@univ-nantes.fr}{benoit.sevi@univ-nantes.fr}\\
        
        \vspace{9cm}
        
        {\large \textbf{HOUSSAIS Rémi, QUINTIN DE KERCADIO Pierre}}
        
        \vfill
        
        {\large \today}
        
    \end{center}
\end{titlepage}
\begingroup
\hypersetup{linkcolor=black}
\tableofcontents
\endgroup

\newpage


# Chocs permanents vs. choc transitoires: une analyse exploratoire
```{r}
library(stats)
library(ggplot2)


simulate_ar1 <- function(phi, choc_value, choc_time = 100, n = 200) {
  Y <- numeric(n)
  eps <- rnorm(n, mean = 0, sd = 1)
  
  for (t in 2:n) {
    Y[t] <- phi * Y[t - 1] + eps[t]
    if (t == choc_time) {
      Y[t] <- Y[t] + choc_value
    }
  }
  return(Y)
}

set.seed(123)


phi_vals <- c(0.5, 0.9, 1.0)
chocs <- c(20, 40, -20, -40)

# Stocker les résultats dans une data.frame
results <- data.frame()

for (choc in chocs) {
  for (phi in phi_vals) {
    serie <- simulate_ar1(phi, choc)
    df <- data.frame(
      t = 1:200,
      Y = serie,
      phi = paste0("phi = ", phi),
      choc = paste0("Choc = ", choc)
    )
    results <- rbind(results, df)
  }
}
ggplot(results, aes(x = t, y = Y, color = phi)) +
  geom_line() +
  facet_wrap(~choc, scales = "free_y") +
  labs(title = "Impact de chocs à t=100 pour différentes valeurs de ϕ₁",
       x = "Temps", y = "Y_t") +
  theme_minimal() +
  theme(legend.position = "top")


library(ggplot2)
simulate_ar1 <- function(phi, choc_value, choc_time = 100, n = 200) {
  Y <- numeric(n)
  eps <- rnorm(n, mean = 0, sd = 1)
  
  for (t in 2:n) {
    Y[t] <- phi * Y[t - 1] + eps[t]
    if (t == choc_time) {
      Y[t] <- Y[t] + choc_value
    }
  }
  return(Y)
}


```

**Interprétation**

**Lorsque $\phi$=0.5 et $\phi$=0.5 :**

Un choc de +20 ou -20 entraîne une perturbation temporaire, mais la série retrouve rapidement son niveau d'avant-choc, en environ 10 unités de temps. Cela s'explique par le fait qu'un faible ϕϕ signifie une mémoire courte : les valeurs passées influencent peu les valeurs futures, et l'effet du choc s'estompe rapidement.

**Lorsque $\phi$=0.9 $\phi$=0.9 :**

Pour un même choc, le retour à l'état initial est bien plus lent, prenant environ 25 unités de temps. Avec une valeur plus élevée de ϕϕ, la série possède une mémoire plus longue, ce qui signifie que les effets du choc persistent plus longtemps avant de s'atténuer.

**Lorsque $\phi$=1.0 $\phi$=1.0 (marche aléatoire) :**

La série ne revient pas à une moyenne stable après le choc. Une fois l’impact survenu, la trajectoire du processus est modifiée de façon durable. Cela illustre bien le fait qu’un AR(1) avec ϕ=1ϕ=1 est non stationnaire : il ne possède pas de force de rappel vers une moyenne fixe, et l’effet du choc se propage indéfiniment avec des fluctuations autour du nouveau niveau atteint.


Enfin, lorsque l’intensité du choc passe de 20 à 40 (ou de -20 à -40), les écarts par rapport à l’état initial sont plus marqués, et le temps nécessaire pour s’en rapprocher à nouveau augmente. Cela confirme que plus le choc est fort, plus le processus aura du mal à retrouver son équilibre, surtout pour des valeurs élevées de ϕϕ.



# TS vs DS : simulation de processus

## Loi $N$(0,1/4)

### Seed(123)

```{r}

library(ggplot2)
set.seed(123)

n <- 200  
sigma2 <- 1/4  

epsilon <- rnorm(n, mean = 0, sd = sqrt(sigma2))  # Génération du bruit blanc


Y_DT <- numeric(n)
Y_TS <- numeric(n)

for (t in 1:n) {
  Y_DT[t] <- 0.2 * t + epsilon[t]  
  if (t == 1) {
    Y_TS[t] <- epsilon[t]  
  } else {
    Y_TS[t] <- 0.2 + Y_TS[t - 1] + epsilon[t]  
  }
}

# Création du DataFrame
data <- data.frame(
  Time = rep(1:n, 2),
  Value = c(Y_DT, Y_TS),
  Process = rep(c("DT: Yt = 0.2t + εt", "TS: Yt = 0.2 + Yt-1 + εt"), each = n)
)

# Graphique
ggplot(data, aes(x = Time, y = Value, color = Process)) +
  geom_line() +
  labs(title = "Comparaison entre un processus déterministe et un processus stochastique dans une loi N(0,1/4)",
       x = "Temps",
       y = "Valeur de la série") +
  theme_minimal()
  
```

**Interprétation**

Le graphique compare deux séries soumises à un même bruit N(0,1/4): un processus déterministe ($Y_t = 0.2t + \varepsilon_t$  ), et un processus stochastique (  $Y_t = 0.2 + Y_{t-1} + \varepsilon_t$ ).

La série déterministe suit une tendance linéaire régulière, perturbée temporairement par de faibles chocs : elle est stationnaire autour d’une tendance.
En revanche, la série stochastique accumule les chocs dans le temps, ce qui entraîne des écarts de plus en plus marqués : elle est non stationnaire avec des effets de chocs permanents.

### Seed(287)


```{r}
set.seed(287)

n <- 200  
sigma2 <- 1/4  

epsilon <- rnorm(n, mean = 0, sd = sqrt(sigma2))  # Génération du bruit blanc


Y_DT <- numeric(n)
Y_TS <- numeric(n)

for (t in 1:n) {
  Y_DT[t] <- 0.2 * t + epsilon[t]  
  if (t == 1) {
    Y_TS[t] <- epsilon[t]  
  } else {
    Y_TS[t] <- 0.2 + Y_TS[t - 1] + epsilon[t]  
  }
}

# Création du DataFrame
data <- data.frame(
  Time = rep(1:n, 2),
  Value = c(Y_DT, Y_TS),
  Process = rep(c("DT: Yt = 0.2t + εt", "TS: Yt = 0.2 + Yt-1 + εt"), each = n)
)

# Graphique
ggplot(data, aes(x = Time, y = Value, color = Process)) +
  geom_line() +
  labs(title = "Comparaison entre un processus déterministe et un processus stochastique dans une loi N(0,1/4)",
       x = "Temps",
       y = "Valeur de la série") +
  theme_minimal()
```

**Interprétation**

Avec ce nouveau tirage aléatoire, on retrouve la même dynamique générale : le processus déterministe suit une tendance régulière, alors que le processus stochastique évolue de manière plus irrégulière. Cette fois, le DT reste au-dessus du TS sur presque toute la période, ce qui montre que la trajectoire du processus stochastique dépend fortement des chocs initiaux. Le fond reste inchangé : le DT absorbe les chocs, le TS les cumule dans le temps.

### Seed(986)

```{r}
set.seed(986)

n <- 200  
sigma2 <- 1/4  

epsilon <- rnorm(n, mean = 0, sd = sqrt(sigma2))  # Génération du bruit blanc


Y_DT <- numeric(n)
Y_TS <- numeric(n)

for (t in 1:n) {
  Y_DT[t] <- 0.2 * t + epsilon[t]  
  if (t == 1) {
    Y_TS[t] <- epsilon[t]  
  } else {
    Y_TS[t] <- 0.2 + Y_TS[t - 1] + epsilon[t]  
  }
}

# Création du DataFrame
data <- data.frame(
  Time = rep(1:n, 2),
  Value = c(Y_DT, Y_TS),
  Process = rep(c("DT: Yt = 0.2t + εt", "TS: Yt = 0.2 + Yt-1 + εt"), each = n)
)

# Graphique
ggplot(data, aes(x = Time, y = Value, color = Process)) +
  geom_line() +
  labs(title = "Comparaison entre un processus déterministe et un processus stochastique dans une loi N(0,1/4)",
       x = "Temps",
       y = "Valeur de la série") +
  theme_minimal()
```

**Interprétation** 

Avec ce nouveau tirage aléatoire, on retrouve la même dynamique générale: le processus déterministe (rouge) suit une tendance régulière, alors que le processus stochastique (bleu) évolue de manière plus irrégulière. Cette fois, le TS dépasse nettement le DT à partir du milieu de la période, ce qui montre une nouvelle fois que la trajectoire du processus stochastique dépend fortement des chocs accumulés. Le fond reste inchangé : le DT absorbe les chocs, le TS les cumule dans le temps.




### Conclusion

La dynamique globale reste constante : le processus déterministe suit toujours une tendance régulière perturbée temporairement par le bruit, tandis que le processus stochastique affiche une trajectoire plus irrégulière, qui s’écarte progressivement en fonction des chocs accumulés.
Dans certaines simulations, le TS reste en dessous du DT, dans d’autres il le dépasse, ce qui illustre parfaitement la forte sensibilité du processus stochastique à la réalisation des chocs initiaux.
Ces trois graphiques confirment que le DT est stable et prévisible, alors que le TS est instable et imprévisible à long terme, malgré des conditions de départ identiques

## Loi $N$(0,1/2)

### Seed(123)
```{r}
set.seed(123)

# Paramètres
n <- 200  # Nombre d'observations
sigma2 <- 1/2  # Variance du bruit

epsilon <- rnorm(n, mean = 0, sd = sqrt(sigma2))  # Génération du bruit blanc

# Simulation des processus
Y_DT <- numeric(n)
Y_TS <- numeric(n)

for (t in 1:n) {
  Y_DT[t] <- 0.2 * t + epsilon[t]  
  if (t == 1) {
    Y_TS[t] <- epsilon[t]  
  } else {
    Y_TS[t] <- 0.2 + Y_TS[t - 1] + epsilon[t]  
  }
}

# Création du DataFrame
data <- data.frame(
  Time = rep(1:n, 2),
  Value = c(Y_DT, Y_TS),
  Process = rep(c("DT: Yt = 0.2t + εt", "TS: Yt = 0.2 + Yt-1 + εt"), each = n)
)

# Graphique
ggplot(data, aes(x = Time, y = Value, color = Process)) +
  geom_line() +
  labs(title = "Comparaison entre un processus déterministe et un processus stochastique dans une loi N(0,1/2)",
       x = "Temps",
       y = "Valeur de la série") +
  theme_minimal()

```

**Interprétation**

Avec ce nouveau tirage aléatoire et une variance du bruit plus élevée, on observe une dynamique toujours similaire : le processus déterministe progresse régulièrement selon sa tendance linéaire, tandis que le processus stochastique présente une trajectoire plus irrégulière. Ici, les deux séries restent proches sur l’ensemble de l’échantillon, mais on note que le TS dépasse légèrement le DT en fin de période. Cela montre que l’augmentation de la variance amplifie la variabilité des deux séries, mais affecte davantage le TS qui accumule les chocs. Le DT, lui, reste globalement stable autour de sa pente.

### Seed(287)

```{r}
set.seed(287)

# Paramètres
n <- 200  # Nombre d'observations
sigma2 <- 1/2  # Variance du bruit

epsilon <- rnorm(n, mean = 0, sd = sqrt(sigma2))  # Génération du bruit blanc

# Simulation des processus
Y_DT <- numeric(n)
Y_TS <- numeric(n)

for (t in 1:n) {
  Y_DT[t] <- 0.2 * t + epsilon[t]  
  if (t == 1) {
    Y_TS[t] <- epsilon[t]  
  } else {
    Y_TS[t] <- 0.2 + Y_TS[t - 1] + epsilon[t]  
  }
}

# Création du DataFrame
data <- data.frame(
  Time = rep(1:n, 2),
  Value = c(Y_DT, Y_TS),
  Process = rep(c("DT: Yt = 0.2t + εt", "TS: Yt = 0.2 + Yt-1 + εt"), each = n)
)

# Graphique
ggplot(data, aes(x = Time, y = Value, color = Process)) +
  geom_line() +
  labs(title = "Comparaison entre un processus déterministe et un processus stochastique dans une loi N(0,1/2)",
       x = "Temps",
       y = "Valeur de la série") +
  theme_minimal()
```

**Interprétation**

Avec ce nouveau tirage, on observe une configuration différente : le processus déterministe dépasse clairement le processus stochastique sur presque toute la période. Cela illustre à nouveau que, bien que les deux séries partagent la même pente moyenne (0.2), le comportement du TS est fortement influencé par les chocs initiaux. Ici, ces chocs ont freiné la progression de la série stochastique, tandis que la série déterministe, insensible à la mémoire, poursuit une trajectoire plus régulière. Le contraste est net en fin de période, où le DT atteint des niveaux beaucoup plus élevés que le TS.

### Seed(986)

```{r}
set.seed(986)

# Paramètres
n <- 200  # Nombre d'observations
sigma2 <- 1/2  # Variance du bruit

epsilon <- rnorm(n, mean = 0, sd = sqrt(sigma2))  # Génération du bruit blanc

# Simulation des processus
Y_DT <- numeric(n)
Y_TS <- numeric(n)

for (t in 1:n) {
  Y_DT[t] <- 0.2 * t + epsilon[t]  
  if (t == 1) {
    Y_TS[t] <- epsilon[t]  
  } else {
    Y_TS[t] <- 0.2 + Y_TS[t - 1] + epsilon[t]  
  }
}

# Création du DataFrame
data <- data.frame(
  Time = rep(1:n, 2),
  Value = c(Y_DT, Y_TS),
  Process = rep(c("DT: Yt = 0.2t + εt", "TS: Yt = 0.2 + Yt-1 + εt"), each = n)
)

# Graphique
ggplot(data, aes(x = Time, y = Value, color = Process)) +
  geom_line() +
  labs(title = "Comparaison entre un processus déterministe et un processus stochastique dans une loi N(0,1/2)",
       x = "Temps",
       y = "Valeur de la série") +
  theme_minimal()
```

**Interprétation**

Avec ce troisième tirage, le processus stochastique est nettement au dessus sur le déterministe dès la moitié de la période. On observe ici une forte montée du TS, liée à une succession de chocs positifs qui, une fois cumulés, entraînent un écart important par rapport au DT. À l’inverse, le processus déterministe reste fidèle à sa tendance linéaire, avec des fluctuations modérées. Cette configuration montre à quel point le processus stochastique peut diverger rapidement selon les chocs, même si les deux séries partagent la même pente moyenne.



### Conclusion 

Pour une loi $N$(0,1/2) nous pouvons remarquer que la dynamique reste constante comme sur la loi $N$(0,1/4). En effet, le processus déterministe suit toujours une tendance régulière, seulement perturbée de manière temporaire par un bruit modéré. En revanche, le processus stochastique  présente une trajectoire plus irrégulière, qui s’écarte progressivement à mesure que les chocs s’accumulent dans le temps.
Dans certaines simulations, le TS reste en dessous du DT, dans d’autres il le dépasse nettement, ce qui illustre parfaitement la forte sensibilité du processus stochastique à la réalisation des chocs aléatoires.
Ces trois graphiques confirment que le DT est stable, tandis que le TS reste instable.


## Loi $N$(0,1)

### Seed(123)

```{r}
set.seed(123)

# Paramètres
n <- 200  # Nombre d'observations
sigma2 <- 1  # Variance du bruit

epsilon <- rnorm(n, mean = 0, sd = sqrt(sigma2))  # Génération du bruit blanc

# Simulation des processus
Y_DT <- numeric(n)
Y_TS <- numeric(n)

for (t in 1:n) {
  Y_DT[t] <- 0.2 * t + epsilon[t]  
  if (t == 1) {
    Y_TS[t] <- epsilon[t]  
  } else {
    Y_TS[t] <- 0.2 + Y_TS[t - 1] + epsilon[t]  
  }
}

# Création du DataFrame
data <- data.frame(
  Time = rep(1:n, 2),
  Value = c(Y_DT, Y_TS),
  Process = rep(c("DT: Yt = 0.2t + εt", "TS: Yt = 0.2 + Yt-1 + εt"), each = n)
)

# Graphique
ggplot(data, aes(x = Time, y = Value, color = Process)) +
  geom_line() +
  labs(title = "Comparaison entre un processus déterministe et un processus stochastique dans une loi N(0,1)",
       x = "Temps",
       y = "Valeur de la série") +
  theme_minimal()

```

**Interprétation**

Pour cette loi $N$(0,1), la dynamique reste la même observée que les deux autres lois. En effet,le processus déterministe suit une trajectoire croissante régulière, alors que le processus stochastique fluctue davantage et s’en écarte par moments. Ici, le TS dépasse nettement le DT autour de t=100. avant de redescendre et de se rapprocher en fin de période. 


### Seed(287)

```{r}
set.seed(287)

# Paramètres
n <- 200  # Nombre d'observations
sigma2 <- 1  # Variance du bruit

epsilon <- rnorm(n, mean = 0, sd = sqrt(sigma2))  # Génération du bruit blanc

# Simulation des processus
Y_DT <- numeric(n)
Y_TS <- numeric(n)

for (t in 1:n) {
  Y_DT[t] <- 0.2 * t + epsilon[t]  
  if (t == 1) {
    Y_TS[t] <- epsilon[t]  
  } else {
    Y_TS[t] <- 0.2 + Y_TS[t - 1] + epsilon[t]  
  }
}

# Création du DataFrame
data <- data.frame(
  Time = rep(1:n, 2),
  Value = c(Y_DT, Y_TS),
  Process = rep(c("DT: Yt = 0.2t + εt", "TS: Yt = 0.2 + Yt-1 + εt"), each = n)
)

# Graphique
ggplot(data, aes(x = Time, y = Value, color = Process)) +
  geom_line() +
  labs(title = "Comparaison entre un processus déterministe et un processus stochastique dans une loi N(0,1)",
       x = "Temps",
       y = "Valeur de la série") +
  theme_minimal()
```

**Interprétation**

Avec ce nouveau tirage aléatoire, ,nous pouvons remarquer le processus déterministe est toujours stable dans le temps et est au dessus du stochastique sur l’ensemble de la période. Nous pouvons remarquer, que à partiur de T=90, TS chute brutalement et reste en dessous du processus déterministe.


### Seed(986)

```{r}
set.seed(986)

# Paramètres
n <- 200  # Nombre d'observations
sigma2 <- 1  # Variance du bruit

epsilon <- rnorm(n, mean = 0, sd = sqrt(sigma2))  # Génération du bruit blanc

# Simulation des processus
Y_DT <- numeric(n)
Y_TS <- numeric(n)

for (t in 1:n) {
  Y_DT[t] <- 0.2 * t + epsilon[t]  
  if (t == 1) {
    Y_TS[t] <- epsilon[t]  
  } else {
    Y_TS[t] <- 0.2 + Y_TS[t - 1] + epsilon[t]  
  }
}

# Création du DataFrame
data <- data.frame(
  Time = rep(1:n, 2),
  Value = c(Y_DT, Y_TS),
  Process = rep(c("DT: Yt = 0.2t + εt", "TS: Yt = 0.2 + Yt-1 + εt"), each = n)
)

# Graphique
ggplot(data, aes(x = Time, y = Value, color = Process)) +
  geom_line() +
  labs(title = "Comparaison entre un processus déterministe et un processus stochastique dans une loi N(0,1)",
       x = "Temps",
       y = "Valeur de la série") +
  theme_minimal()
```

**Interprétation**

Avec ce nouveau tirage aléatoire, ,nous pouvons remarquer le processus déterministe est toujours stable dans le temps et est en dessous du stochastique sur l’ensemble de la période. Nous pouvons remarquer, que à partiur de T=90, TS monte brutalement et reste au dessus du processus déterministe.


### Conclusion

Pour une loi $N$(0,1), la dynamique globale reste constante : le processus déterministe suit toujours une tendance régulière perturbée temporairement par le bruit, tandis que le processus stochastique affiche une trajectoire plus irrégulière, qui s’écarte progressivement en fonction des chocs accumulés.
Avec une variance plus élevée, ces écarts deviennent encore plus marqués. Le TS peut rester en retrait comme dans le deuxième graphique, coller au DT comme dans le premier, ou bien le dépasser largement comme dans le troisième.
Cette variabilité illustre parfaitement la forte sensibilité du processus stochastique à la réalisation des chocs, qui s’amplifie avec la taille des perturbations.




## Conlusion générale 

Pour conclure sur cette partie, nous pouvons remarquer que pour chaque série c'était plus ou moins la m^meme tendance. En effet, le processus déterministe a toujours suivi la tendnace quelque soit la loi N ou le seed, et le processus stochastique a toujours été plus sensible aux fluctuations. 




# Régressions fallacieuses 

## $n$ = 200 et $N$ = 5000
```{r}
set.seed(123)


n <- 200       
N <- 5000     
rejets <- numeric(N)

for (i in 1:N) {
  
  X <- cumsum(rnorm(n))
  Y <- cumsum(rnorm(n))
  

  model <- lm(Y ~ X)
  p_value <- summary(model)$coefficients[2, 4]  
  

  rejets[i] <- ifelse(p_value < 0.05, 1, 0)
}

pourcentage_rejets <- mean(rejets) * 100
cat("Pourcentage de rejets de H0 (β1 = 0) au seuil de 5% :", round(pourcentage_rejets, 2), "%\n")

```

**Interprétation**
Avec ce premeir test avec $n$=200 et $N$=500, nous obtenons un taux de rejet de HO de 83.52%, par conséquent même si les séries sont indépendantes, nous rejetons HO très souvent. Cela s’explique par le fait que les marches aléatoires sont non stationnaires, en raison de la présence d’une racine unitaire dans leur dynamique.


Pour pouvoir observer les differnces nousn allons varier $n$ et $N$


## Variations du nombre d'observations,$n$, et du nombre de séries générée, $N$. 

### Augmentation et diminution de $n$

#### $n$ = 50 et $N$ = 5000

```{r}
set.seed(238)


n <- 50    
N <- 5000   
rejets <- numeric(N)

for (i in 1:N) {
  
  X <- cumsum(rnorm(n))
  Y <- cumsum(rnorm(n))
  
  
  model <- lm(Y ~ X)
  p_value <- summary(model)$coefficients[2, 4]  
  
  
  rejets[i] <- ifelse(p_value < 0.05, 1, 0)
}

pourcentage_rejets <- mean(rejets) * 100
cat("Pourcentage de rejets de H0 (β1 = 0) au seuil de 5% :", round(pourcentage_rejets, 2), "%\n")
```

**Interprétation**

Lorsqu'on diminue le nombre d'observation $n$ à 50, nous pouvons remarquer que nous obtenons un taux de rejet de HO de 66.14%. Ce qui est inférieur à celui précédent. Par conséquent, quand le nombre d'observation diminue alors on rejete moins à tort. 


#### $n$ = 500 et $N$ = 5000


```{r}
set.seed(238)


n <- 500   
N <- 5000   
rejets <- numeric(N)

for (i in 1:N) {
  
  X <- cumsum(rnorm(n))
  Y <- cumsum(rnorm(n))
  
  
  model <- lm(Y ~ X)
  p_value <- summary(model)$coefficients[2, 4]  
  
  
  rejets[i] <- ifelse(p_value < 0.05, 1, 0)
}

pourcentage_rejets <- mean(rejets) * 100
cat("Pourcentage de rejets de H0 (β1 = 0) au seuil de 5% :", round(pourcentage_rejets, 2), "%\n")
```

**Interprétation**

Lorsqu'on augmente le nombre d'observation $n$ à 50°, nous pouvons remarquer que nous obtenons un taux de rejet de HO de 89.2%. Ce qui est supérieur aux deux précédents. Par conséquent, quand le nombre d'observation augmente alors on rejete plus à tort. 


### Augmentation et diminution de $N$

#### $n$ = 200 et $N$ = 2000

```{r}
set.seed(238)


n <- 200   
N <- 2000   
rejets <- numeric(N)

for (i in 1:N) {
  
  X <- cumsum(rnorm(n))
  Y <- cumsum(rnorm(n))
  
  
  model <- lm(Y ~ X)
  p_value <- summary(model)$coefficients[2, 4]  
  
  
  rejets[i] <- ifelse(p_value < 0.05, 1, 0)
}

pourcentage_rejets <- mean(rejets) * 100
cat("Pourcentage de rejets de H0 (β1 = 0) au seuil de 5% :", round(pourcentage_rejets, 2), "%\n")
```

**Interprétation**

Lorsqu'on diminue le nombre de séries générées $N$ à 2000, nous pouvons remarquer que nous obtenons un taux de rejet de HO de 83.6%. Ce qui est légérement au dessus du modèle initial. 

#### $n$ = 200 et $N$ = 10000
```{r}
set.seed(238)


n <- 200   
N <- 10000   
rejets <- numeric(N)

for (i in 1:N) {
  
  X <- cumsum(rnorm(n))
  Y <- cumsum(rnorm(n))
  
  
  model <- lm(Y ~ X)
  p_value <- summary(model)$coefficients[2, 4]  
  
  
  rejets[i] <- ifelse(p_value < 0.05, 1, 0)
}

pourcentage_rejets <- mean(rejets) * 100
cat("Pourcentage de rejets de H0 (β1 = 0) au seuil de 5% :", round(pourcentage_rejets, 2), "%\n")
```

**Interprétation**

Lorsqu'on augmente le nombre de séries générées $N$ à 10000, nous pouvons remarquer que nous obtenons un taux de rejet de HO de 83.49%. Ce qui est légérement en dessous du modèle initial. 


## Conclusion générale 

Par conséquent, le fait de changer le nombre de séries générées ne varie pas énormément le taux de rejet de H0. Alors que, le fait de changer à lla baisse ou à la hausse le nombre d'observations fait varier énormément le taux de rejet de H0








# Distribution de la statistique de test de Dickey-Fuller pour le modèle sans constante ni tendance via la méthode de Monte Carlo

## Distribution du modèle (1) sans constante ni tendance $Y_t = Y_{t-1} + \varepsilon_t$

```{r}
set.seed(123)

# Paramètres
n <- 100         # Longueur de la série
N <- 10000       # Nombre de simulations
t_stats <- numeric(N)

for (i in 1:N) {
  eps <- rnorm(n)
  Y <- cumsum(eps)  # Y_t = Y_{t-1} + ε_t
  
  dY <- diff(Y)            # ΔY_t
  Y_lag <- Y[-n]           # Y_{t-1}
  
  model <- lm(dY ~ 0 + Y_lag)  # régression sans constante
  t_stats[i] <- summary(model)$coefficients[1, 3]  # t-statistique
}

# Valeurs critiques empiriques
quantiles <- quantile(t_stats, probs = c(0.10, 0.05, 0.01))
print(round(quantiles, 3))

# Histogramme
hist(t_stats, breaks = 50, col = "darkgreen", border = "white",
     main = "Distribution Monte Carlo du modèle (1)",
     xlab = "Valeurs de la statistique t")

# Ajout des lignes verticales pour les quantiles critiques
abline(v = quantiles[1], col = "orange", lwd = 2, lty = 2)
abline(v = quantiles[2], col = "red", lwd = 2, lty = 2)
abline(v = quantiles[3], col = "darkred", lwd = 2, lty = 2)

# Ajout d'une légende
legend("topright", legend = c("10%", "5%", "1%"),
       col = c("orange", "red", "darkred"),
       lty = 2, lwd = 2, title = "Seuils")

```


**Interprétation**

Pour ce modèle, sans constante ni tendance nous pouvons observer plusieurs indications. 
En effet, les valeurs critiques issues de la simulation du modèle (1) sont très proches de celles de la table théorique de Dickey-Fuller :

| Seuil     | Monte Carlo | Table DF (n = 100) |
|-----------|-------------|--------------------|
| 10%       | -1.630      | -1.61              |
| 5%        | -1.988      | -1.95              |
| 1%        | -2.633      | -2.60              |


En simulant 10 000 séries de 100 observations d’un processus à racine unitaire sans constante ni tendance, nous obtenons une distribution empirique de la statistique t du test de Dickey-Fuller. Les seuils de rejet à 10 %, 5 % et 1 % obtenus sont respectivement de -1.630, -1.988 et -2.633. Et lorsque l’on compare ces valeurs à celles issues de la table théorique de Dickey-Fuller, on observe une très bonne similitude avec des valeurs respectives de -1.61, -1.95 et -2.60 pour les mêmes seuils de rejet. 

## Distribution du modèle (2) avec $\delta_0 = 5$


```{r}
set.seed(123)

n_simulations <- 10000
n_obs <- 100

# Fonction pour générer une marche aléatoire avec constante
generate_random_walk_avec_const <- function(n, delta0) {
  Yt <- numeric(n)
  Yt[1] <- delta0  # Initialisation avec la constante
  for (t in 2:n) {
    Yt[t] <- Yt[t-1] + rnorm(1)
  }
  return(Yt)
}

# Fonction pour exécuter la simulation et afficher les résultats
simulation_cst <- function(delta0) {
  set.seed(123)  # Réinitialisation de la graine pour reproductibilité
  
  t_stats <- numeric(n_simulations)  # Réinitialisation à chaque appel
  
  for (i in 1:n_simulations) {
    Yt <- generate_random_walk_avec_const(n_obs, delta0)
    
    dYt <- diff(Yt)
    Yt_lag <- Yt[-n_obs]
    
    model <- lm(dYt ~ Yt_lag)  # Régression avec constante par défaut
    t_stats[i] <- summary(model)$coefficients[2, 3]  # Récupération du t-stat
  }
  
  # Calcul des quantiles (valeurs critiques)
  quantiles <- quantile(t_stats, c(0.10, 0.05, 0.01))
  
  # Affichage graphique
  hist(t_stats, breaks = 50, probability = TRUE, col = "royalblue", border = "white",
       main = paste("Distribution Monte Carlo des t-stat de Dickey-Fuller (δ0 =", delta0, ")"),
       xlab = "Valeur de la statistique t", ylab = "Densité")
  lines(density(t_stats), col = "royalblue", lwd = 2)
  abline(v = quantiles, col = c("orange", "red", "darkred"), lwd = 2, lty = 2)
  legend("topright", legend = c("Densité estimée", "Quantile 10%", "Quantile 5%", "Quantile 1%"),
         col = c("royalblue", "orange", "red", "darkred"), lwd = 2, cex = 0.5, lty = c(1, 2, 2, 2))
  
  # Affichage des valeurs critiques
  cat("Valeurs critiques obtenues pour δ0 =", delta0, ":\n")
  print(quantiles)
}


simulation_cst(delta0 = 5)
#simulation_cst(delta0 = 10)
```

**Interprétation**


En introduisant une constante $\delta_0 = 5$ dans le processus simulé, nous observons que la distribution empirique de la statistique t est nettement déplacée vers la gauche par rapport à la distribution théorique attendue pour le test de Dickey-Fuller avec constante.

| Seuil     | Monte Carlo | Table DF (n = 100) |
|-----------|-------------|--------------------|
| 10%       | -2.590     | -1.61              |
| 5%        | -2.885     | -1.95              |
| 1%        | -3.476      | -2.60              |

En effet, nous pouvons observer que pour $\delta_0 = 5$ les seuils de rejet s'éloignent de ceux de la table de Dickey-Fuller. 

Par conséquent, d'après cette première analyse nous pouvons observer que l'instauration d'un delta est importante dans les simulations. Nous allons le vérifier avec l'instauration de delta à 10. 


## Distribution du modèle (3) avec une constante $\delta_0 = 10$


```{r}
set.seed(123)

n_simulations <- 10000
n_obs <- 100

# Fonction pour générer une marche aléatoire avec constante
generate_random_walk_avec_const <- function(n, delta0) {
  Yt <- numeric(n)
  Yt[1] <- delta0  # Initialisation avec la constante
  for (t in 2:n) {
    Yt[t] <- Yt[t-1] + rnorm(1)
  }
  return(Yt)
}

# Fonction pour exécuter la simulation et afficher les résultats
simulation_cst <- function(delta0) {
  set.seed(123)  # Réinitialisation de la graine pour reproductibilité
  
  t_stats <- numeric(n_simulations)  # Réinitialisation à chaque appel
  
  for (i in 1:n_simulations) {
    Yt <- generate_random_walk_avec_const(n_obs, delta0)
    
    dYt <- diff(Yt)
    Yt_lag <- Yt[-n_obs]
    
    model <- lm(dYt ~ Yt_lag)  # Régression avec constante par défaut
    t_stats[i] <- summary(model)$coefficients[2, 3]  # Récupération du t-stat
  }
  
  # Calcul des quantiles (valeurs critiques)
  quantiles <- quantile(t_stats, c(0.10, 0.05, 0.01))
  
  # Affichage graphique
  hist(t_stats, breaks = 50, probability = TRUE, col = "royalblue", border = "white",
       main = paste("Distribution Monte Carlo des t-stat de Dickey-Fuller (δ0 =", delta0, ")"),
       xlab = "Valeur de la statistique t", ylab = "Densité")
  lines(density(t_stats), col = "royalblue", lwd = 2)
  abline(v = quantiles, col = c("orange", "red", "darkred"), lwd = 2, lty = 2)
  legend("topright", legend = c("Densité estimée", "Quantile 10%", "Quantile 5%", "Quantile 1%"),
         col = c("royalblue", "orange", "red", "darkred"), lwd = 2, cex = 0.5, lty = c(1, 2, 2, 2))
  
  # Affichage des valeurs critiques
  cat("Valeurs critiques obtenues pour δ0 =", delta0, ":\n")
  print(quantiles)
}


#simulation_cst(delta0 = 5)
simulation_cst(delta0 = 10)
```


**Interprétation**

En introduisant une constante $\delta_0 = 10$ dans le processus simulé, nous observons que la distribution empirique de la statistique t est nettement déplacée vers la gauche par rapport à la distribution théorique attendue pour le test de Dickey-Fuller avec constante.

| Seuil     | Monte Carlo | Table DF (n = 100) |
|-----------|-------------|--------------------|
| 10%       | -2.590     | -1.61              |
| 5%        | -2.885    | -1.95              |
| 1%        | -3.476      | -2.60              |


Pour cette secponde simulation avec constante, nous pouvons également remarquer que le fait d'introduire une constante influence grandement grandement les résultats de la simulation. 


## Conclusion générale

```{r}
set.seed(123)

n <- 100
N <- 10000

# Initialisation
t_none <- numeric(N)
t_d5 <- numeric(N)
t_d10 <- numeric(N)

# Simulation : modèle sans constante
for (i in 1:N) {
  eps <- rnorm(n)
  Y <- cumsum(eps)
  dY <- diff(Y)
  Y_lag <- Y[-n]
  model <- lm(dY ~ 0 + Y_lag)
  t_none[i] <- summary(model)$coefficients[1, 3]
}

# Simulation : modèle avec constante δ₀ = 5
for (i in 1:N) {
  eps <- rnorm(n)
  Y <- numeric(n)
  Y[1] <- 5
  for (t in 2:n) {
    Y[t] <- Y[t - 1] + eps[t]
  }
  dY <- diff(Y)
  Y_lag <- Y[-n]
  model <- lm(dY ~ Y_lag)
  t_d5[i] <- summary(model)$coefficients[2, 3]
}

# Simulation : modèle avec constante δ₀ = 10
for (i in 1:N) {
  eps <- rnorm(n)
  Y <- numeric(n)
  Y[1] <- 10
  for (t in 2:n) {
    Y[t] <- Y[t - 1] + eps[t]
  }
  dY <- diff(Y)
  Y_lag <- Y[-n]
  model <- lm(dY ~ Y_lag)
  t_d10[i] <- summary(model)$coefficients[2, 3]
}

# Densités
dens_none <- density(t_none)
dens_5 <- density(t_d5)
dens_10 <- density(t_d10)

# Graphique final
plot(dens_none, col = "darkgreen", lwd = 2,
     main = expression("Distribution des statistiques t : sans constante vs " * delta[0] * " = 5 et 10"),
     xlab = "Valeurs de la statistique t", ylab = "Density",
     xlim = c(-6, 4), ylim = c(0, 0.55))
lines(dens_5, col = "purple", lwd = 2, lty = 2)
lines(dens_10, col = "black", lwd = 2, lty = 3)

legend("topright",
       legend = c("Sans constante", expression(delta[0] == 5), expression(delta[0] == 10)),
       col = c("darkgreen", "purple", "black"),
       lty = c(1, 2, 3), lwd = 2, bty = "n")

```

**Interprétation**

Concernant le graphqiue ci dessus, nous observer comme indiqué plus haut, une certaine différence entre le fait de rajouter une constante et de pas en avoir. En effet, avoir une constance entraine que la courbe se décalle vers la gauche. 

Néanmoins, concernnat la différence de  $\delta_0 = 5$ et $\delta_0 = 10$, il n'existe pas dedifférence visuelle. Les deux courbes se suivent.

**Tableau de comparaison**

| Seuil | Sans constante | $\delta_0 = 5$ | $\delta_0 = 10$ | Table DF (n = 100) |
|-------|----------------|--------|---------|---------------------|
| 10%   | -1.630          | -2.590 | -2.590  | -1.61               |
| 5%    | -1.988          | -2.885 | -2.885  | -1.95               |
| 1%    | -2.633          | -3.476 | -3.476  | -2.60               |

Comme nous pouvons l'observer avec ce tableau, il existe une réélle différence entre le fait d'avoir une constant et non. En effet, avec une constante on s'éloigne des résultats de la table de Dickey-Fuller. 

Néanmoins, entre $\delta_0 = 5$ et $\delta_0 = 10$ il n'existe pas de différence donc la différence se fait suelement sur le fait d'ajouter une constante ou non.




# Analyse de  la série temporelle du PIB des USA sur la période 1990-2023 

## Représentation graphique du PIB US avec les zones ombrées pour les récessions
```{r}
library(ggplot2)
library(readr)
library(dplyr)
library(tibbletime)
library(scales)
library(lubridate)
library(tseries)
library(urca)
```

```{r}
# Charger le fichier
load("data/GDP-US-1990-2023.RData")

# Vérifier le nom de l'objet chargé
ls()
```

### Définition des zonées ombrées sous-periode 1990-2019
```{r}
df_Y_us2 <- df_Y_us[c(-121:-140),]
#str(df_Y_us2)
recessions <- data.frame(
  start = as.Date(c("1990-07-01", "2001-03-01", "2007-12-01")),
  end = as.Date(c("1991-03-31", "2001-11-30", "2009-06-30"))
)
```

### Graphique
```{r}
ggplot(df_Y_us2, aes(x = Date, y = PIB)) +
  geom_line(color = "blue", size = 1) + # Tracer la ligne du PIB
  # Ajouter des zones ombrées pour les récessions
  geom_rect(data = recessions, aes(xmin = start, xmax = end, ymin = -Inf, ymax = Inf), 
            fill = "gray", alpha = 0.5, inherit.aes = FALSE) +
  labs(title = "Évolution du PIB des États-Unis (1990-2019)",
       x = "Année", y = "PIB (en milliards de dollars)") +
  theme_minimal() + # Style minimaliste
  scale_x_date(labels = date_format("%Y"), breaks = "2 years") # Étiquettes de l'axe X
```
**Interprétation**

Tout d'abord, les zones grises représentent les périodes de récession aux États-Unis, telles que définies par le National Bureau of Economic Research. Elles correspondent à des phases où l’activité économique s’est contractée, entraînant un ralentissement voire une baisse du PIB. Visuellement, ces zones permettent de repérer les moments où la dynamique de croissance est interrompue ou infléchie, comme lors de la crise de 2008, qui se traduit ici par une chute marquée du PIB. Elles offrent donc un repère visuel essentiel pour relier les évolutions économiques aux chocs conjoncturels majeurs.


On remarque également que chaque zone grisée correspond à une baisse temporaire du PIB ou à une phase de stagnation, contrastant avec le reste de la période où la croissance est continue et soutenue. Cela souligne clairement l’impact des récessions sur la trajectoire de l’économie américaine.

## ACF et PACF de la série

### ACF
```{r}
#conversion en série temporelle
ts_pib <- ts(df_Y_us2$PIB, start = c(1990, 1), frequency = 4) 


acf(ts_pib, main = "ACF du PIB des États-Unis de 1990 à 2019")
```
**Interprétation**

Le graphique de l’autocorrélation (ACF) du PIB américain sur la période 1990–2019 met en évidence une structure d’une série non stationnaire. L’autocorrélation au premier décalage est très élevée (proche de 1), et les coefficients décroissent lentement sans jamais devenir non significatifs. Cette persistance de la mémoire indique que les valeurs passées du PIB influencent fortement ses valeurs futures, ce qui est caractéristique d’un processus avec racine unitaire.


### PACF 
```{r}
# PACF
pacf(ts_pib, main = "PACF du PIB des États-Unis de 1990 à 2019")
```
**Interprétation**

Le graphique de la fonction d’autocorrélation partielle (PACF) du PIB en niveau présente une structure très nette : seul le premier lag est significatif, tandis que tous les autres sont proches de zéro et non significatifs au-delà du seuil de confiance. Ce type de découplage brutal après le premier retard est typique d’un processus de type AR(1) non stationnaire, donc d'une marche aléatoire. Ce graphqiue est également typique des bruits blancs.



## Mise en œuvre de la procédure de test de racine unitaire avec le test de Dickey-Fuller simple puis le test de Dickey-Fuller augmenté.

### Modèle 3: Avec constante et tendance
```{r}
# Modèle 3: Avec tendance et constante
cat("\n--- TEST DF MODÈLE 3: AVEC TENDANCE ET CONSTANTE ---\n")
# Test de Dickey-Fuller simple
df_test_modele3 <- ur.df(ts_pib, type = "trend", lags = 0)
summary(df_test_modele3)
# Test de Dickey-Fuller augmenté (avec retards sélectionnés automatiquement)
adf_test_modele3 <- ur.df(ts_pib, type = "trend", selectlags = "AIC")
summary(adf_test_modele3)
```
**Interprétation**

Le test de Dickey Fuller augmenté nous confirme cela  -1,6862 > -3,43, nous rejetons $H₀$ uniquement au seuil de 10%.

Conclusion principale : la série contient toujours une racine unitaire nous pouvons passer au modèle 2.


### Modèle 2: Avec constante et sans tendance
```{r}
df_test_modele2 <- ur.df(ts_pib, type = "drift", lags = 0)
summary(df_test_modele2)

adf_test_modele2 <- ur.df(ts_pib, type = "drift", selectlags = "AIC")
summary(adf_test_modele2)
```
**Interprétation**

La statistique de test est supérieure à la valeur critique de -2.88 à 5%, donc nous ne rejetons pas l'hypothèse nulle de racine unitaire. Cela suggère que la série n'est pas stationnaire. Le second modèle nous amène à la même conclusion. Nous devons donc passer au modèle 1 (sans constante ni tendance).

### Modèle 1: Sans constante et tendance

```{r}
#Test de Dickey-Fuller simple
    df_test_modele1 <- ur.df(ts_pib, type = "none", lags = 0)
    summary(df_test_modele1)
    
# Test de Dickey-Fuller augmenté
    adf_test_modele1 <- ur.df(ts_pib, type = "none", selectlags = "AIC")
    summary(adf_test_modele1)
```
**Interprétation**

Les deux tests indiquent que la série possède une racine unitaire, ce qui signifie qu’elle n'est pas stationnaire en niveau. En effet la statistique de test est supérieur à l'ensemble des valeurs critique (exemple avec le DF augmenté: 5.25 > -1.95).

Peu importe le modèle testé (avec ou sans lags), l’hypothèse nulle de non-stationnarité n'est jamais rejetée. La série est donc non stationnaire, ce qui confirme ce qui a été dit avant avec l'ACF et PACF.


## Test de stationarité de KPSS

```{r}
kpss_test <- kpss.test(ts_pib, null = "Trend")

print(kpss_test)
```
**Interprétation**

La p-value est faible (0.01 < 0.05), on rejette donc l’hypothèse nulle de stationnarité, la série est non stationnaire.
Les deux tests confirment que la série est non stationnaire.



## Analyse avec la période globale (1990-2023)

### Graphique
```{r}
recessions <- data.frame(
  start = as.Date(c("1990-07-01", "2001-03-01", "2007-12-01", "2020-02-01")),
  end = as.Date(c("1991-03-31", "2001-11-30", "2009-06-30", "2020-04-30"))
)


# Tracer le PIB avec les zones ombrées pour les récessions
ggplot(df_Y_us, aes(x = Date, y = PIB)) +
  geom_line(color = "blue", size = 1) + # Tracer la ligne du PIB
  # Ajouter des zones ombrées pour les récessions
  geom_rect(data = recessions, aes(xmin = start, xmax = end, ymin = -Inf, ymax = Inf), 
            fill = "gray", alpha = 0.5, inherit.aes = FALSE) +
  labs(title = "Évolution du PIB des États-Unis (1990-2023)",
       x = "Année", y = "PIB (en milliards de dollars)") +
  theme_minimal() + # Style minimaliste
  scale_x_date(labels = date_format("%Y"), breaks = "2 years") # Étiquettes de l'axe X
```
**Interprétation**

Concernant le graphique sur la période complète, on observe les mêmes dynamiques que précédemment : les zones grisées correspondent aux périodes de récession définies par le NBER, durant lesquelles le PIB marque soit un ralentissement, soit une baisse temporaire. À cela s’ajoute désormais la récession liée à la crise du Covid-19 en 2020, bien visible sur le graphique par une chute marquée du PIB. Cette observation confirme que ces phases conjoncturelles ont un impact clair et immédiat sur la trajectoire du PIB américain.


### ACF
```{r}
#conversion en série temporelle
ts_pib2 <- ts(df_Y_us$PIB, start = c(1990, 1), frequency = 4) 
# ACF
acf(ts_pib2, main = "ACF du PIB des États-Unis de 1990 à 2023")
```
**Interprétation**

L’ACF sur la période 1990–2023 présente la même structure qu’auparavant : les autocorrélations sont très élevées au début, et décroissent lentement sans devenir rapidement nulles. Cette persistance confirme que la série est fortement non stationnaire, avec un processus avec racine unitaire.
Par conséquent, le choc lié à la crise du Covid-19, ne modifie pas la structure fondamentale de la série.

### PACF
```{r}
# PACF
pacf(ts_pib2, main = "PACF du PIB des États-Unis de 1990 à 2023")
```

**Interprétation**

Le graphique de la PACF confirme les observations faites précédemment : seul le premier lag est significatif, tandis que les suivants sont proches de zéro et non significatifs. Cette structure suggère que le PIB suit toujours une dynamique de type AR(1) non stationnaire. C'est toujours typique des bruits blancs. 

### Choix du modèle adéquat

#### Modèle 3: Avec constante et tendance
```{r}
# Modèle 3: Avec tendance et constante
cat("\n--- TEST DF MODÈLE 3: AVEC TENDANCE ET CONSTANTE ---\n")
# Test de Dickey-Fuller simple
df_test_modele3 <- ur.df(ts_pib2, type = "trend", lags = 0)
summary(df_test_modele3)
# Test de Dickey-Fuller augmenté (avec retards sélectionnés automatiquement)
adf_test_modele3 <- ur.df(ts_pib2, type = "trend", selectlags = "AIC")
summary(adf_test_modele3)
```
**Interprétation**

Les résultats du test montrent une p-value de 0.02779 pour la statistique F, ce qui suggère que le modèle est globalement significatif. Cependant, en ce qui concerne la stationnarité, la valeur de la statistique de test est de -2.5593, tandis que la valeur critique à 5% est -3.43. Comme la statistique de test est supérieure à la valeur critique, on ne rejette pas l'hypothèse nulle de présence d'une racine unitaire. Cela signifie que la série est non stationnaire.




#### Modèle 2: Avec constante et sans tendance
```{r}
df_test_modele2 <- ur.df(ts_pib2, type = "drift", lags = 0)
summary(df_test_modele2)

adf_test_modele2 <- ur.df(ts_pib2, type = "drift", selectlags = "AIC")
summary(adf_test_modele2)
```
**Interprétation**

La statistique des deux tests est de 0.5829 et 0.7809, qui est supérieure à la valeur critique de -2.88 à 5%, donc nous ne rejetons pas l'hypothèse nulle de présence d'une racine unitaire. Cela suggère que la série est non stationnaire. Par conséquent, nous passons au modèle 1


#### Modèle 1: Sans constante et tendance

```{r}
#Test de Dickey-Fuller simple
    df_test_modele1 <- ur.df(ts_pib2, type = "none", lags = 0)
    summary(df_test_modele1)
    
# Test de Dickey-Fuller augmenté
    adf_test_modele1 <- ur.df(ts_pib2, type = "none", selectlags = "AIC")
    summary(adf_test_modele1)
```
**Interprétation**

Les deux tests indiquent que la série n'est pas stationnaire en niveau, car elle présente une racine unitaire. En effet, la statistique de test est supérieure à l'ensemble des valeurs critiques (par exemple, avec le test de Dickey-Fuller augmenté : 5.8175 > -1.95).

Peu importe le modèle testé (avec ou sans retards), l'hypothèse nulle de présence d'une racine unitaire n'est jamais rejetée. Cela confirme que la série est non stationnaire, ce qui est également cohérent avec les résultats obtenus précédemment à partir de l'ACF et PACF.

###Test de stationarité de KPSS

```{r}
kpss_test <- kpss.test(ts_pib2, null = "Trend")

print(kpss_test)
```

**Interprétation**

Le test de KPSS appliqué au PIB sur la période 1990–2023 donne une statistique de test de 0.2339, avec une p-value inférieure à 0.01.

Cela signifie que l’on rejette l’hypothèse nulle de stationnarité autour d’une tendance, même au seuil de 1%. Par cosnéquent, le test suggère que la série n’est pas stationnaire, ce qui vient confirmer les résultats des tests de Dickey-Fuller ainsi que l’analyse visuelle de l’ACF et de la PACF.

### Conclusion de la période globale (1990-2023)

Après avoir appliqué l’ensemble des tests de stationnarité sur la période étendue de 1990 à 2023, nous parvenons aux mêmes conclusions que précédemment (1990–2019) : la série du PIB reste non stationnaire et présente une racine unitaire, quels que soient les modèles testés (avec ou sans constante, avec ou sans tendance).

Les résultats des tests de Dickey-Fuller (simples et augmentés), tout comme ceux du test de KPSS, confirment la non-stationnarité observée visuellement dans les graphiques ACF et PACF. Ainsi, l’allongement de la période n’altère pas la dynamique structurelle de la série, et vient renforcer les constats établis sur la période initiale.




